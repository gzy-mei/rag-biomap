import os
import pandas as pd
import openai
import shutil
from openpyxl import load_workbook
import tqdm

# === é…ç½® ===
original_file = "/home/gzy/rag-biomap/dataset/VTE-PTE-CTEPHç ”ç©¶æ•°æ®åº“.xlsx"
new_file_dir = "/home/gzy/rag-biomap/dataset/test_two"
# new_file_path = os.path.join(new_file_dir, "VTE-PTE-CTEPHç ”ç©¶æ•°æ®åº“-å®éªŒå®¤æ£€æŸ¥1.xlsx")
# standard_data_path = os.path.join(new_file_dir, "æ ‡å‡†æ•°æ®.xlsx")
new_file_path = os.path.join(new_file_dir, "VTE-PTE-CTEPHç ”ç©¶æ•°æ®åº“-å®éªŒå®¤æ£€æŸ¥2.xlsx")
standard_data_path = os.path.join(new_file_dir, "æ ‡å‡†æ•°æ®2.xlsx")
non_standard_file = "/home/gzy/rag-biomap/dataset/å®éªŒå®¤æ£€æŸ¥æ•°æ®.1.xlsx"
result_dir = "/home/gzy/rag-biomap/dataset/Results"

# OpenAI client é…ç½®
client = openai.OpenAI(
    base_url="http://172.16.55.171:7010/v1",
    api_key="sk-cairi"
)

prompt_template = r"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŒ»ç–—é¢†åŸŸæ•°æ®å¯¹é½åŠ©æ‰‹ï¼Œæ“…é•¿å°†éæ ‡å‡†åŒ–çš„å®éªŒå®¤æ£€æŸ¥æŒ‡æ ‡åç§°æ˜ å°„åˆ°æ ‡å‡†åŒ–çš„å®šä¹‰ã€‚

ä½ çš„ä»»åŠ¡æ˜¯æ¥æ”¶ä¸€ä¸ªæŸ¥è¯¢æ£€éªŒæŒ‡æ ‡åï¼ˆqueryï¼‰å’Œä¸€ä¸ªå€™é€‰æ ‡å‡†æŒ‡æ ‡ååˆ—è¡¨ï¼ˆcandidatesï¼‰ï¼Œç„¶åä»candidatesä¸­æ‰¾åˆ°ä¸queryæœ€åŒ¹é…çš„æŒ‡æ ‡ååŠå…¶å¯¹åº”çš„ç½®ä¿¡åº¦åˆ†æ•°ã€‚

è¯·æ³¨æ„ä»¥ä¸‹åŒ¹é…è§„åˆ™ï¼š
1. **å®Œå…¨åŒ¹é…ä¼˜å…ˆ**ï¼šå¦‚æœqueryä¸candidatesä¸­çš„æŸä¸ªæŒ‡æ ‡åå®Œå…¨ç›¸åŒï¼ˆåŒ…æ‹¬å¤§å°å†™ï¼‰ï¼Œç›´æ¥è¿”å›1.0åˆ†
2. **å¿½ç•¥éå…³é”®ä¿®é¥°è¯**ï¼šå¯ä»¥å¿½ç•¥ï¼ˆqueryï¼‰ä¸­çš„ç¬¦å·ä¿¡æ¯ï¼Œæ¯”å¦‚â˜…ä»¥åŠ*ç­‰ï¼Œä½†éœ€ä¿ç•™æ ¸å¿ƒæŒ‡æ ‡åç§°
3. **åŒä¹‰è¯åŒ¹é…**ï¼šè¯†åˆ«åŒ»å­¦æœ¯è¯­ä¸­çš„åŒä¹‰è¯å…³ç³»ï¼ˆå¦‚"è¡€çº¢è›‹ç™½"å’Œ"è¡€è‰²ç´ "ï¼‰
4. **ç¼©å†™åŒ¹é…**ï¼šèƒ½å¤Ÿå¤„ç†å¸¸è§åŒ»å­¦ç¼©å†™ï¼ˆå¦‚"WBC"åŒ¹é…"ç™½ç»†èƒè®¡æ•°"ï¼‰
5. **ç½®ä¿¡åº¦åˆ†æ•°**ï¼šåˆ†æ•°èŒƒå›´ä¸º(0, 1.0]ï¼Œ1.0è¡¨ç¤ºå®Œç¾åŒ¹é…
6. **æ— åŒ¹é…å¤„ç†**ï¼šè‹¥æ— åˆç†åŒ¹é…åˆ™è¿”å›N/Aå’Œ0.0

è¿”å›æ ¼å¼å¿…é¡»ä¸¥æ ¼ä¸ºJSONï¼ŒåŒ…å« `matched_field_name` å’Œ `score` ä¸¤ä¸ªå­—æ®µã€‚ä¸è¦åŒ…å«```jsonå’Œä»»ä½•é¢å¤–çš„è§£é‡Šã€è¯´æ˜æˆ–æŠ¥é”™ä¿¡æ¯ã€‚


---

**è¾“å…¥ç¤ºä¾‹**ï¼š
Query: "è¡€çº¢è›‹ç™½(*HGB)"
Candidates: ["è¡€çº¢è›‹ç™½ï¼ˆHbï¼‰", "è¡€æ¸…ç™½è›‹ç™½ï¼ˆALBï¼‰", "è‚Œé’™è›‹ç™½Iï¼ˆcTNIï¼‰"]

**è¾“å‡ºç¤ºä¾‹**ï¼š
{
  "matched_field_name": "è¡€çº¢è›‹ç™½ï¼ˆHbï¼‰",
  "score": 0.9
}

---

## å½“å‰ä»»åŠ¡

* Query: {{query}}
* Candidates: {{candidates}}

è¯·è¿”å›JSONæ ¼å¼çš„åŒ¹é…ç»“æœï¼š
"""
# === æ­¥éª¤ 1: å¤åˆ¶åŸå§‹æ–‡ä»¶å¹¶æ·»åŠ å½•å…¥1åˆ— ===
shutil.copyfile(original_file, new_file_path)
wb = load_workbook(new_file_path)
ws = wb["å®éªŒå®¤æ£€æŸ¥"]

header_row = list(ws.iter_rows(min_row=1, max_row=1, values_only=True))[0]
name_col_idx = header_row.index("åç§°") + 1
insert_col_idx = name_col_idx + 1
ws.insert_cols(insert_col_idx)
ws.cell(row=1, column=insert_col_idx, value="å½•å…¥1")
wb.save(new_file_path)

# === æ­¥éª¤ 2: æå–æ ‡å‡†å­—æ®µ ===
df_standard = pd.read_excel(original_file, sheet_name="å®éªŒå®¤æ£€æŸ¥", usecols="E")
df_standard.to_excel(standard_data_path, index=False)

# === æ­¥éª¤ 3: æå–æŒ‡å®šå”¯ä¸€å·ä¸‹çš„éæ ‡å‡†æœ¯è¯­ ===
df_non_standard_all = pd.read_excel(non_standard_file)
df_filtered = df_non_standard_all[df_non_standard_all["å”¯ä¸€å·"] == "zy@ZY050002401765"]
query_terms = df_filtered[["æ£€éªŒæŒ‡æ ‡å", "æ£€éªŒæŒ‡æ ‡å€¼"]].dropna().values.tolist()

# === æ­¥éª¤ 4: è°ƒç”¨ LLM åŒ¹é… ===
from concurrent.futures import ThreadPoolExecutor, as_completed
from collections import defaultdict
from tqdm import tqdm
import json

def llm_match_single(query, value, candidates):
    filled_prompt = prompt_template.replace("{{query}}", query).replace("{{candidates}}", str(candidates))
    try:
        response = client.chat.completions.create(
            model="CAIRI-LLM-reasoner",
            messages=[{"role": "user", "content": filled_prompt}],
            temperature=0,
            presence_penalty=1.5,
            extra_body={"min_p": 0},
        )
        result = json.loads(response.choices[0].message.content.strip())
        matched = result.get("matched_field_name", "N/A")
        return matched, value
    except Exception:
        return "é”™è¯¯", "é”™è¯¯"
candidates = df_standard["åç§°"].dropna().astype(str).tolist()
# === å¤šçº¿ç¨‹æ‰§è¡Œ LLM åŒ¹é…ï¼ˆæ›¿æ¢åŸ for å¾ªç¯ï¼‰ ===
match_map = defaultdict(list)
with ThreadPoolExecutor(max_workers=10) as executor:
    futures = {
        executor.submit(llm_match_single, query, value, candidates): (query, value)
        for query, value in query_terms
    }
    for future in tqdm(as_completed(futures), total=len(futures), desc="ğŸ§  LLMå¤šçº¿ç¨‹åŒ¹é…ä¸­", ncols=80):
        matched, value = future.result()
        match_map[matched].append(value)
# import json
# from collections import defaultdict
# from tqdm import tqdm
#
# candidates = df_standard["åç§°"].dropna().astype(str).tolist()
# match_map = defaultdict(list)
#
# for query, value in tqdm(query_terms, desc="LLMåŒ¹é…ä¸­", ncols=80):
#     filled_prompt = prompt_template.replace("{{query}}", query).replace("{{candidates}}", str(candidates))
#     try:
#         response = client.chat.completions.create(
#             model="CAIRI-LLM-reasoner",
#             messages=[{"role": "user", "content": filled_prompt}],
#             temperature=0,
#             presence_penalty=1.5,
#             extra_body={"min_p": 0},
#         )
#         result = json.loads(response.choices[0].message.content.strip())
#         matched = result.get("matched_field_name", "N/A")
#         if matched != "N/A":
#             match_map[matched].append(value)
#         else:
#             match_map[matched].append("N/A")
#     except Exception as e:
#         match_map["é”™è¯¯"].append("é”™è¯¯")


# === æ­¥éª¤ 5: å†™å…¥åˆ°â€œå½•å…¥1â€åˆ— ===
df_target = pd.read_excel(new_file_path, sheet_name="å®éªŒå®¤æ£€æŸ¥")
if "å½•å…¥1" not in df_target.columns:
    df_target.insert(name_col_idx, "å½•å…¥1", "")

for idx, row in df_target.iterrows():
    field_name = str(row["åç§°"]).strip()
    if field_name in match_map:
        values = match_map[field_name]
        df_target.at[idx, "å½•å…¥1"] = "--".join(map(str, values))
    elif field_name == "nan":
        df_target.at[idx, "å½•å…¥1"] = "NA"
    elif any(field_name == m for m in match_map.keys() if m != "é”™è¯¯" and m != "N/A"):
        continue
    elif field_name not in match_map:
        df_target.at[idx, "å½•å…¥1"] = "NA"
    else:
        df_target.at[idx, "å½•å…¥1"] = "é”™è¯¯"

with pd.ExcelWriter(new_file_path, engine="openpyxl", mode="a", if_sheet_exists="replace") as writer:
    df_target.to_excel(writer, sheet_name="å®éªŒå®¤æ£€æŸ¥", index=False)

print("âœ… æ‰€æœ‰æ­¥éª¤å·²å®Œæˆã€‚")

