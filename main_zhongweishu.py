import sys
import os
import re
import argparse
import pandas as pd
import numpy as np
import jieba
import tqdm
import json
from openai import OpenAI
from typing import List, Dict
#è¿›è¡Œæ•°æ®é›†å¤„ç†
from data_description.invoke_data_manipulaltion import extract_name_columns_from_multiple_sheets
from data_description.invoke_Non_standard_data import extract_first_row_to_csv
#è¿›è¡Œå‘é‡åŒ–
from Build_an_index.invoke_Build_index import get_embedding, build_index_from_csv
from Build_an_index.invoke_Non_standard_data_Build_index import vectorize_header_terms
#è®¡ç®—å‘é‡ç›¸ä¼¼åº¦
from sklearn.metrics.pairwise import cosine_similarity
from rank_bm25 import BM25Okapi
#è¿›åº¦æ¡å±•ç¤º
from tqdm import tqdm
# ç”¨äºå®ç°å¤šçº¿ç¨‹å¹¶å‘å¤„ç†ã€‚
from concurrent.futures import ThreadPoolExecutor, as_completed

# åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
client = OpenAI(
    base_url="http://172.16.55.171:7010/v1",
    #base_url="http://10.0.1.194:7010/v1",
    api_key="sk-cairi"
)

# é…ç½®å‚æ•°
CONFIG = {
    "llm_model": "CAIRI-LLM-reasoner",
    "non_standard_excel": "dataset/å¯¼å‡ºæ•°æ®ç¬¬1~1000æ¡æ•°æ®_ç—…æ¡ˆé¦–é¡µ-.xlsx",
    "standard_excel": "dataset/VTE-PTE-CTEPHç ”ç©¶æ•°æ®åº“.xlsx",
    "header_csv": "data_description/test/header_row.csv",
    "standard_terms_csv": "data_description/test/æ ‡å‡†æœ¯è¯­_ç—…æ¡ˆé¦–é¡µ.csv",
    "header_vectors": "Build_an_index/test/header_terms.npy",
    "standard_vectors": "Build_an_index/test/standard_terms.npy",
    "output_excel": "dataset/åŒ¹é…ç»“æœå¯¹æ¯”.xlsx",
    "output_dir": "dataset/Matching_Results_Comparison"
}

#åˆå§‹åŒ–ç›®å½•ç»“æ„ï¼š æ ¹æ®é…ç½®æ–‡ä»¶CONFIGä¸­çš„è·¯å¾„ï¼Œè‡ªåŠ¨åˆ›å»ºè¿™äº›è·¯å¾„æ‰€åœ¨çš„æ–‡ä»¶å¤¹ç›®å½•ï¼ˆå¦‚æœç›®å½•ä¸å­˜åœ¨æ»´è¯ï¼‰
def initialize_directories():
    for path in [CONFIG["header_csv"], CONFIG["header_vectors"]]:
        os.makedirs(os.path.dirname(path), exist_ok=True)

#å¤„ç†éæ ‡å‡†æ•°æ®ï¼ˆè¡¨å¤´ä¿¡æ¯ï¼‰
def process_non_standard_data() -> List[str]:
    #from data_description.invoke_Non_standard_data import extract_first_row_to_csv
    # å…ˆè°ƒç”¨extract_first_row_to_csvï¼Œç¡®ä¿CSVç”ŸæˆæˆåŠŸ
    #ç»“æœç”Ÿæˆï¼šdata_description/test/header_row.csv
    if not extract_first_row_to_csv(CONFIG["non_standard_excel"], CONFIG["header_csv"]):
        raise RuntimeError("éæ ‡å‡†æ•°æ®å¤„ç†å¤±è´¥")
    # è°ƒç”¨å°è£…å¥½çš„å‘é‡åŒ–å‡½æ•°
    #from Build_an_index.invoke_Non_standard_data_Build_index import vectorize_header_terms
    #ç»“æœç”Ÿæˆï¼šBuild_an_index/test/header_terms.npy
    vectorize_header_terms(
        CONFIG["header_csv"],
        CONFIG["header_vectors"],
        failed_log_path="Build_an_index/test/header_terms_failed.csv"
    )
    # è¿”å›æ‰€æœ‰æ–‡æœ¬åˆ—è¡¨
    return pd.read_csv(CONFIG["header_csv"], header=None)[0].tolist()

#å¤„ç†æ ‡å‡†æœ¯è¯­æ•°æ®ï¼ˆçŸ¥è¯†åº“ï¼‰
def process_standard_data() -> List[str]:
    """
    å¤„ç†æ ‡å‡†æœ¯è¯­æ•°æ®ï¼šæå–å¤šä¸ª sheet çš„â€œåç§°â€åˆ— â†’ ä¿å­˜CSV â†’ å‘é‡åŒ– â†’ è¿”å›æœ¯è¯­åˆ—è¡¨
    """
    # âœ… æå–å¤šä¸ª sheet çš„â€œåç§°â€åˆ—
    target_sheets = ["æ‚£è€…åŸºçº¿ä¿¡æ¯", "ç—…æ¡ˆé¦–é¡µä¿¡æ¯"]
    success = extract_name_columns_from_multiple_sheets(
        CONFIG["standard_excel"],
        CONFIG["standard_terms_csv"],
        target_sheets=target_sheets,
        target_column="åç§°"
    )
    if not success:
        raise RuntimeError("æ ‡å‡†æœ¯è¯­æå–å¤±è´¥")

    # âœ… åŠ è½½CSVå¹¶æå–æœ¯è¯­ï¼ˆå³â€œå†…å®¹â€åˆ—ï¼‰
    df = pd.read_csv(CONFIG["standard_terms_csv"])
    if "å†…å®¹" not in df.columns:
        raise ValueError("æ ‡å‡†æœ¯è¯­CSVç¼ºå°‘ 'å†…å®¹' åˆ—")
    terms = df["å†…å®¹"].dropna().astype(str).tolist()
    print(f"âœ… æˆåŠŸåŠ è½½æ ‡å‡†æœ¯è¯­ï¼Œå…± {len(terms)} æ¡")

    # âœ… å‘é‡åŒ–â€œå†…å®¹â€åˆ—
    build_index_from_csv(
        CONFIG["standard_terms_csv"],     # ç›´æ¥ä½¿ç”¨åŸCSV
        CONFIG["standard_vectors"],       # ä¿å­˜å‘é‡è·¯å¾„
        column_index=2,                   # â€œå†…å®¹â€åˆ—åœ¨CSVä¸­çš„ä½ç½®
        verbose=False
    )
    return terms


def detect_similarity_method(func):
    def wrapper(*args, **kwargs):
        method_name = func.__name__.lower()
        if "bm25" in method_name:
            CONFIG["similarity_method"] = "BM25"
        elif "cosine" in method_name:
            CONFIG["similarity_method"] = "Cosine"
        else:
            CONFIG["similarity_method"] = "Unknown"
        return func(*args, **kwargs)
    return wrapper


prompt_template = r"""
ä½ æ˜¯åŒ»ç–—æ•°æ®æ ‡å‡†åŒ–åŠ©æ‰‹ã€‚è¯·ä»ä¸‹åˆ—å€™é€‰æœ¯è¯­ä¸­ï¼Œé€‰æ‹©ä¸ç»™å®šåŸå§‹è¡¨å¤´æœ€åŒ¹é…çš„ä¸€ä¸ªã€‚

åŒ¹é…è§„åˆ™ï¼š
1. å®Œå…¨ä¸€è‡´ä¼˜å…ˆï¼›
2. å¿½ç•¥æ— æ„ä¹‰è¯ï¼ˆå¦‚â€œå‡ºé™¢â€ã€â€œç¼–å·â€ã€â€œ3â€ç­‰ï¼‰ï¼Œä½†ä¿ç•™å¦‚â€œå…¥é™¢â€â€œç—…æƒ…â€ï¼›
3. è‹¥æ— åˆé€‚åŒ¹é…ï¼Œè¿”å› N/A å’Œ 0.0 åˆ†ï¼›
4. åˆ†æ•°ä¸º (0, 1.0]ï¼ŒåŒ¹é…è¶Šæ¥è¿‘ï¼Œåˆ†æ•°è¶Šé«˜ï¼›

âš ï¸ã€è¾“å‡ºè¦æ±‚ã€‘
ä¸¥æ ¼ä»…è¾“å‡ºå¦‚ä¸‹æ ¼å¼ï¼Œä¸èƒ½æœ‰è§£é‡Šã€ä»£ç å—ã€æ¢è¡Œæˆ–å…¶å®ƒå†…å®¹ï¼š
{"matched_field_name": "xxx", "score": x.x}

---

åŸå§‹è¡¨å¤´: {{h_text}}
å€™é€‰æœ¯è¯­: {{top_3}}
è¯·è¾“å‡ºï¼š
"""


def generate_with_llm(prompt: str) -> str:
    try:
        response = client.chat.completions.create(
            model=CONFIG["llm_model"],
            messages=[{"role": "user", "content": prompt}],
            temperature=0,
            presence_penalty=1.5,
            extra_body={"min_p": 0},
        )

        message_obj = response.choices[0].message
        raw_content = None
        if hasattr(message_obj, "content") and message_obj.content:
            raw_content = message_obj.content.strip()
        elif hasattr(message_obj, "reasoning_content") and message_obj.reasoning_content:
            raw_content = message_obj.reasoning_content.strip()
        else:
            raw_content = ""

        # âœ… åŸºç¡€æ¸…æ´—ï¼šå»é™¤ markdown JSON åŒ…è£¹
        if raw_content.startswith("```json"):
            raw_content = re.sub(r"^```json", "", raw_content).strip()
            raw_content = re.sub(r"```$", "", raw_content).strip()
        elif raw_content.startswith("```"):
            raw_content = re.sub(r"^```", "", raw_content).strip()
            raw_content = re.sub(r"```$", "", raw_content).strip()

        # âœ… æ‰©å±•æ¸…æ´—ï¼šä¸­æ–‡ç¬¦å· + æ‹¼å†™ä¿®å¤ + å†—ä½™å­—æ®µ
        raw_content = raw_content.replace("â€œ", "\"").replace("â€", "\"")
        raw_content = raw_content.replace("ï¼Œ", ",").replace("ï¼š", ":")
        raw_content = raw_content.replace("matchee", "matched_field_name")
        if '"matched_field_' in raw_content:
            raw_content = raw_content.replace('"matched_field_"', '"matched_field_name"')
        raw_content = raw_content.rstrip("ã€‚")

        # âœ… è‡ªåŠ¨è¡¥å…¨ç¼ºå¤±çš„å¤§æ‹¬å·
        if raw_content.count("{") > raw_content.count("}"):
            raw_content += "}"
        elif raw_content.count("{") < raw_content.count("}"):
            raw_content = raw_content[:raw_content.rfind("}")+1]

        # âœ… æ­£åˆ™æå– JSON ä¸»ä½“
        # âœ… æ›´ä¸¥æ ¼çš„æ­£åˆ™æå– JSON ä¸»ä½“ï¼Œç¡®ä¿åªæå–ä¸€æ®µ
        try:
            json_match = re.findall(r"\{.*?\}", raw_content.strip(), re.DOTALL)
            if len(json_match) != 1:
                print(f"âš ï¸ è¿”å›äº† {len(json_match)} æ®µ JSONï¼Œæ— æ³•åˆ¤æ–­ä½¿ç”¨å“ªæ®µ")
                print(f"Promptï¼š{prompt}")
                print(f"åŸå§‹è¿”å›å†…å®¹ï¼š{raw_content}")
                return "è°ƒç”¨å¤±è´¥"

            parsed = json.loads(json_match[0])
            matched = parsed.get("matched_field_name", "")
            if matched == "N/A":
                return ""
            return matched

            parsed = json.loads(raw_content)
            matched = parsed.get("matched_field_name", "")
            if matched == "N/A":
                return ""
            return matched

        except Exception as e:


            print("âš ï¸ JSONè§£æå¤±è´¥ï¼")
            print(f"Promptï¼š{prompt}")
            print(f"è¿”å›åŸæ–‡ï¼š{raw_content}")
            print(f"å¼‚å¸¸ä¿¡æ¯ï¼š{e}")
            return "è°ƒç”¨å¤±è´¥"

    except Exception as e:
        print(f"âš ï¸ LLMè°ƒç”¨å¤±è´¥ï¼š{e}")
        return "è°ƒç”¨å¤±è´¥"


# threshold_ratio = 0.34
@detect_similarity_method
def calculate_similarities_bm25() -> List[Dict]:
    header_texts = pd.read_csv(CONFIG["header_csv"], header=None)[0].dropna().astype(str).tolist()
    standard_texts = pd.read_csv(CONFIG["standard_terms_csv"])["å†…å®¹"].dropna().astype(str).tolist()
    tokenized_corpus = [list(jieba.cut(text)) for text in standard_texts]
    bm25 = BM25Okapi(tokenized_corpus)

    results = []
    global_scores = []  # âœ… è®°å½•æ‰€æœ‰è¡¨å¤´çš„æœ€å¤§BM25å¾—åˆ†

    def process_single_header(h_text: str) -> Dict:
        query = list(jieba.cut(h_text))
        scores = bm25.get_scores(query)   # å½“å‰è¡¨å¤´è®¡ç®—çš„å‘é‡ç›¸ä¼¼åº¦æ•°ç»„

        max_score = max(scores)  # âœ… å½“å‰è¿™ä¸ªè¡¨å¤´çš„æœ€é«˜å¾—åˆ†
        global_scores.append(max_score)  # âœ… å­˜å…¥åˆ—è¡¨

        top_3_indices = np.argsort(scores)[-3:][::-1]
        top_3 = [standard_texts[i] for i in top_3_indices]
        top_scores = [scores[i] for i in top_3_indices]
        top_score = top_scores[0]

        max_global_score = max(global_scores)   # æ‰€æœ‰è¡¨å¤´è®¡ç®—çš„å…¶æœ€é«˜å‘é‡ç›¸ä¼¼åº¦æ•°ç»„
        median_global_score = np.median(global_scores)


        if top_score < median_global_score:
            return {
                "åŸå§‹è¡¨å¤´": h_text,
                "å€™é€‰æœ¯è¯­": top_3,
                "LLMé€‰æ‹©": "",  # ä¸è°ƒç”¨LLM
                "æœ€é«˜ç›¸ä¼¼åº¦": round(top_score, 4),
                "æœ€é«˜åˆ†ç›¸å¯¹æ¯”ä¾‹ï¼ˆå½“å‰/maxï¼‰": round(top_score / max_global_score, 4) if max_global_score != 0 else 0,
                "æ˜¯å¦è°ƒç”¨LLM": "å¦"
            }
        else:
            prompt = prompt_template.replace("{{h_text}}", h_text).replace("{{top_3}}",
                                                                           json.dumps(top_3, ensure_ascii=False))
            llm_choice_result = generate_with_llm(prompt)

            # åˆ¤æ–­æ˜¯å¦è°ƒç”¨æˆåŠŸå¹¶è¿”å›å€¼
            if llm_choice_result == "è°ƒç”¨å¤±è´¥":
                final_choice = "è°ƒç”¨å¤±è´¥"
            else:
                final_choice = llm_choice_result.strip()

            return {
                "åŸå§‹è¡¨å¤´": h_text,
                "å€™é€‰æœ¯è¯­": top_3,
                "LLMé€‰æ‹©": final_choice,
                "æœ€é«˜ç›¸ä¼¼åº¦": round(top_score, 4),
                "æœ€é«˜åˆ†ç›¸å¯¹æ¯”ä¾‹ï¼ˆå½“å‰/maxï¼‰": round(top_score / max_global_score, 4) if max_global_score != 0 else 0,
                "æ˜¯å¦è°ƒç”¨LLM": "æ˜¯"
            }
    def process_single_header_with_index(index, h_text):
        result = process_single_header(h_text)
        return index, result

    # æŒ‰åŸå§‹é¡ºåºåˆå§‹åŒ–ç©ºåˆ—è¡¨
    results = [None] * len(header_texts)

    with ThreadPoolExecutor(max_workers=20) as executor:
        futures = {
            executor.submit(process_single_header_with_index, idx, h_text): idx
            for idx, h_text in enumerate(header_texts)
        }

        with tqdm(total=len(header_texts), desc="ğŸ§  LLMåŒ¹é…ä¸­", ncols=80) as pbar:
            for future in as_completed(futures):
                try:
                    idx, result = future.result()
                    results[idx] = result
                except Exception as e:
                    future_idx = futures[future]
                    print(f"âš ï¸ è¡¨å¤´å¤„ç†å¤±è´¥ï¼ˆindex={future_idx}ï¼‰: {e}")
                finally:
                    pbar.update(1)

    return results

def save_results(results: List[Dict]):
    results = [r for r in results if r is not None]
    df = pd.DataFrame(results)
    print("ä¿å­˜å‰çš„åˆ—åï¼š", df.columns.tolist())

    # åˆ é™¤ä¸éœ€è¦çš„åˆ—
    df.drop(columns=[col for col in ["å¹³å‡ç›¸ä¼¼åº¦", "åŒ¹é…æˆåŠŸ"] if col in df.columns], inplace=True)

    # åŠ è½½ GT æ ‡å‡†ç­”æ¡ˆï¼ˆè·³è¿‡è¡¨å¤´ï¼‰
    gt_path = "/home/gzy/rag-biomap/dataset/GT.xlsx"
    gt_df = pd.read_excel(gt_path, header=0)

    if gt_df.shape[1] < 2:
        raise ValueError("GT.xlsx å¿…é¡»è‡³å°‘åŒ…å«ä¸¤åˆ—ï¼Œç¬¬äºŒåˆ—ä¸ºæ ‡å‡†ç­”æ¡ˆ")

    gt_answers = gt_df.iloc[:, 1].fillna("").astype(str).tolist()
    df["GTæ ‡å‡†ç­”æ¡ˆ"] = pd.Series(gt_answers[:len(df)])

    # åŒ¹é…åˆ¤æ–­
    # df["æ˜¯å¦åŒ¹é…GT"] = df.apply(lambda row: row["LLMé€‰æ‹©"].strip() == row["GTæ ‡å‡†ç­”æ¡ˆ"].strip(), axis=1)

    def normalize_text(s):
        if not isinstance(s, str):
            return ""
        # å»é™¤ç©ºæ ¼ã€ä¸­æ–‡è‹±æ–‡å†’å·ã€å¥å·ã€æ¢è¡Œç­‰å·®å¼‚
        s = s.strip()
        s = s.replace("ï¼š", ":")  # ä¸­æ–‡å†’å·æ¢æˆè‹±æ–‡
        s = s.replace("ã€‚", ".")
        s = s.replace("\n", "")
        s = s.replace("\r", "")
        s = s.replace(" ", "")
        return s

    df["æ˜¯å¦åŒ¹é…GT"] = df.apply(
        lambda row: normalize_text(row["LLMé€‰æ‹©"]) == normalize_text(row["GTæ ‡å‡†ç­”æ¡ˆ"]),
        axis=1
    )


    # ç»Ÿè®¡ä¿¡æ¯
    total_accuracy = df["æ˜¯å¦åŒ¹é…GT"].mean()
    gt_empty_count = sum(df["GTæ ‡å‡†ç­”æ¡ˆ"] == "")
    llm_empty = df["LLMé€‰æ‹©"] == ""
    gt_empty = df["GTæ ‡å‡†ç­”æ¡ˆ"] == ""
    llm_not_empty = df["LLMé€‰æ‹©"] != ""

    llm_empty_and_gt_empty = df[llm_empty & gt_empty].shape[0]
    llm_empty_total = llm_empty.sum()
    llm_not_empty_total = llm_not_empty.sum()
    llm_not_empty_gt_empty = df[llm_not_empty & gt_empty].shape[0]
    llm_empty_gt_not_empty = df[llm_empty & ~gt_empty].shape[0]

    # åˆ›å»ºç»Ÿè®¡ä¿¡æ¯DataFrame
    stats_data = {
        "ç»Ÿè®¡æŒ‡æ ‡": [
            "llmé€‰æ‹©ä¸GTæ ‡å‡†ç­”æ¡ˆåŒ¹é…å‡†ç¡®ç‡",
            "GTæ ‡å‡†ç­”æ¡ˆä¸­ç©ºå€¼ä¸ªæ•°",
            "llmé€‰æ‹©ä¸ºç©ºï¼ŒGTä¹Ÿä¸ºç©ºçš„åŒ¹é…æˆåŠŸæ•°é‡",
            "llmé€‰æ‹©ä¸ºç©ºçš„æ•°é‡",
            "llmé€‰æ‹©éç©ºçš„æ•°é‡",
            "llmé€‰æ‹©éç©ºï¼Œä½†GTæ˜¯ç©ºçš„æ•°é‡",
            "llmé€‰æ‹©ä¸ºç©ºï¼ŒGTä¸ä¸ºç©ºçš„æ•°é‡"
        ],
        "æ•°å€¼": [
            total_accuracy,
            gt_empty_count,
            llm_empty_and_gt_empty,
            llm_empty_total,
            llm_not_empty_total,
            llm_not_empty_gt_empty,
            llm_empty_gt_not_empty
        ]
    }
    stats_df = pd.DataFrame(stats_data)

    # å°†ç»Ÿè®¡ä¿¡æ¯å†™å…¥Excelçš„ç¬¬12-15åˆ—ï¼ˆL-Oåˆ—ï¼‰
    with pd.ExcelWriter(os.path.join(CONFIG["output_dir"], "ä¸­ä½æ•°.xlsx"), engine="openpyxl") as writer:
        df.to_excel(writer, sheet_name="åŒ¹é…ç»“æœ", index=False)
        stats_df.to_excel(writer, sheet_name="åŒ¹é…ç»“æœ", startcol=11, startrow=1, index=False, header=False)

    # æ§åˆ¶å°è¾“å‡ºï¼ˆè¾…åŠ©ç¡®è®¤ï¼‰
    print(f"âœ… ç»“æœå·²ä¿å­˜åˆ° {os.path.join(CONFIG['output_dir'], 'ä¸­ä½æ•°.xlsx')}")
    print(f"ğŸ“Š åŒ¹é…å‡†ç¡®ç‡ï¼š{total_accuracy:.6f}")
    print(f"ğŸ“Š GTä¸ºç©ºå€¼ï¼š{gt_empty_count}ï¼Œllmé€‰æ‹©ä¸ºç©ºæ•°é‡ï¼š{llm_empty_total}")
    print(f"ğŸ“Š llmé€‰æ‹©ä¸ºç©º && GTä¸ºç©ºï¼ˆåŒ¹é…ï¼‰ï¼š{llm_empty_and_gt_empty}")
    print(f"ğŸ“Š llmé€‰æ‹©éç©º && GTä¸ºç©ºï¼š{llm_not_empty_gt_empty}")
    print(f"ğŸ“Š llmé€‰æ‹©ä¸ºç©º && GTéç©ºï¼š{llm_empty_gt_not_empty}")
    llm_failed_count = sum(df["LLMé€‰æ‹©"] == "è°ƒç”¨å¤±è´¥")
    print(f"â— LLMè°ƒç”¨å¤±è´¥æ•°é‡ï¼š{llm_failed_count}")



def main():
    from Build_an_index.invoke_Build_index import get_embedding


    #è‡ªåŠ¨è¯†åˆ«å½“å‰ä½¿ç”¨çš„åµŒå…¥æ¨¡å‹--æ–¹æ³•ï¼šè·å–get_embeddingå‡½æ•°çš„æ¥æºæ¨¡å—è·¯å¾„ï¼ˆæ¯”å¦‚ bge_m3.pyï¼‰
    module_path = get_embedding.__module__

    print(f"ğŸ“ æ£€æµ‹åˆ° get_embedding æ¥è‡ªæ¨¡å—ï¼š{module_path}")  # âœ… ï¼šè°ƒè¯•è¾“å‡º

    if "bge_m3" in module_path:
        CONFIG["embedding_model"] = "bge-m3"
    elif "nomic_embed_text" in module_path:
        CONFIG["embedding_model"] = "nomic-embed-text"
    elif "mxbai_embed_large" in module_path:
        CONFIG["embedding_model"] = "mxbai-embed-large"
    else:
        CONFIG["embedding_model"] = "unknown"

    #CONFIG["embedding_model"] = get_embedding.__defaults__[0]

    # è‡ªåŠ¨æ£€æµ‹å½“å‰å¯ç”¨çš„ç›¸ä¼¼åº¦è®¡ç®—å‡½æ•°æ˜¯å“ªä¸€ä¸ª-é€šè¿‡å…¨å±€å˜é‡è¡¨globals()æ¥æ£€æµ‹å“ªä¸ªå‡½æ•°å­˜åœ¨ï¼Œæ˜¯æˆ‘æœ‰æ²¡æœ‰â€œå®šä¹‰â€å®ƒã€‚
    if "calculate_similarities_bm25" in globals():
        calculate_similarities = calculate_similarities_bm25
    elif "calculate_similarities_cosine" in globals():
        calculate_similarities = calculate_similarities_cosine
    else:
        raise ValueError(
            "æœªæ£€æµ‹åˆ°ç›¸ä¼¼åº¦è®¡ç®—å‡½æ•°ï¼Œè¯·ç¡®ä¿ä¿ç•™ calculate_similarities_bm25 æˆ– calculate_similarities_cosine ä¸­çš„ä¸€ä¸ª")

    initialize_directories()
    print("ğŸ”„ å¤„ç†éæ ‡å‡†æ•°æ®...")
    header_texts = process_non_standard_data()

    print("ğŸ”„ å¤„ç†æ ‡å‡†çŸ¥è¯†åº“...")
    standard_texts = process_standard_data()

    print("ğŸ” è®¡ç®—ç›¸ä¼¼åº¦å¹¶æ‰§è¡Œç®€åŒ–RAGæµç¨‹...")
    results = calculate_similarities()

#è¿è¡Œç»“æœæ˜¾ç¤ºï¼šğŸ“ å½“å‰ä½¿ç”¨çš„ç›¸ä¼¼åº¦è®¡ç®—æ–¹æ³•ä¸ºï¼š......
    print(f"ğŸ“ å½“å‰ä½¿ç”¨çš„ç›¸ä¼¼åº¦è®¡ç®—æ–¹æ³•ä¸ºï¼š{CONFIG['similarity_method']}")

    print("ğŸ’¾ ä¿å­˜ç»“æœ...")
    save_results(results)

if __name__ == "__main__":
    main()
