import sys
import os
import re
import argparse
import pandas as pd
import numpy as np
import jieba
import tqdm
import json
from openai import OpenAI
from typing import List, Dict
#è¿›è¡Œæ•°æ®é›†å¤„ç†
from data_description.invoke_data_manipulaltion import extract_name_columns_from_multiple_sheets
from data_description.invoke_Non_standard_data import extract_first_row_to_csv
#è¿›è¡Œå‘é‡åŒ–
from Build_an_index.invoke_Build_index import get_embedding, build_index_from_csv
from Build_an_index.invoke_Non_standard_data_Build_index import vectorize_header_terms
#è®¡ç®—å‘é‡ç›¸ä¼¼åº¦
from sklearn.metrics.pairwise import cosine_similarity
from rank_bm25 import BM25Okapi
#è¿›åº¦æ¡å±•ç¤º
from tqdm import tqdm
# ç”¨äºŽå®žçŽ°å¤šçº¿ç¨‹å¹¶å‘å¤„ç†ã€‚
from concurrent.futures import ThreadPoolExecutor, as_completed

# åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
client = OpenAI(
    base_url="http://172.16.55.171:7010/v1",
    #base_url="http://10.0.1.194:7010/v1",
    api_key="sk-cairi"
)

# é…ç½®å‚æ•°
CONFIG = {
    "llm_model": "CAIRI-LLM-reasoner",
    "non_standard_excel": "dataset/å¯¼å‡ºæ•°æ®ç¬¬1~1000æ¡æ•°æ®_ç—…æ¡ˆé¦–é¡µ-.xlsx",
    "standard_excel": "dataset/VTE-PTE-CTEPHç ”ç©¶æ•°æ®åº“.xlsx",
    "header_csv": "data_description/test/header_row.csv",
    "standard_terms_csv": "data_description/test/æ ‡å‡†æœ¯è¯­_ç—…æ¡ˆé¦–é¡µ.csv",
    "header_vectors": "Build_an_index/test/header_terms.npy",
    "standard_vectors": "Build_an_index/test/standard_terms.npy",
    "output_excel": "dataset/åŒ¹é…ç»“æžœå¯¹æ¯”.xlsx",
    "output_dir": "dataset/Matching_Results_Comparison"
}

#åˆå§‹åŒ–ç›®å½•ç»“æž„ï¼š æ ¹æ®é…ç½®æ–‡ä»¶CONFIGä¸­çš„è·¯å¾„ï¼Œè‡ªåŠ¨åˆ›å»ºè¿™äº›è·¯å¾„æ‰€åœ¨çš„æ–‡ä»¶å¤¹ç›®å½•ï¼ˆå¦‚æžœç›®å½•ä¸å­˜åœ¨æ»´è¯ï¼‰
def initialize_directories():
    for path in [CONFIG["header_csv"], CONFIG["header_vectors"]]:
        os.makedirs(os.path.dirname(path), exist_ok=True)

#å¤„ç†éžæ ‡å‡†æ•°æ®ï¼ˆè¡¨å¤´ä¿¡æ¯ï¼‰
def process_non_standard_data() -> List[str]:
    #from data_description.invoke_Non_standard_data import extract_first_row_to_csv
    # å…ˆè°ƒç”¨extract_first_row_to_csvï¼Œç¡®ä¿CSVç”ŸæˆæˆåŠŸ
    #ç»“æžœç”Ÿæˆï¼šdata_description/test/header_row.csv
    if not extract_first_row_to_csv(CONFIG["non_standard_excel"], CONFIG["header_csv"]):
        raise RuntimeError("éžæ ‡å‡†æ•°æ®å¤„ç†å¤±è´¥")
    # è°ƒç”¨å°è£…å¥½çš„å‘é‡åŒ–å‡½æ•°
    #from Build_an_index.invoke_Non_standard_data_Build_index import vectorize_header_terms
    #ç»“æžœç”Ÿæˆï¼šBuild_an_index/test/header_terms.npy
    vectorize_header_terms(
        CONFIG["header_csv"],
        CONFIG["header_vectors"],
        failed_log_path="Build_an_index/test/header_terms_failed.csv"
    )
    # è¿”å›žæ‰€æœ‰æ–‡æœ¬åˆ—è¡¨
    return pd.read_csv(CONFIG["header_csv"], header=None)[0].tolist()

#å¤„ç†æ ‡å‡†æœ¯è¯­æ•°æ®ï¼ˆçŸ¥è¯†åº“ï¼‰
def process_standard_data() -> List[str]:
    """
    å¤„ç†æ ‡å‡†æœ¯è¯­æ•°æ®ï¼šæå–å¤šä¸ª sheet çš„â€œåç§°â€åˆ— â†’ ä¿å­˜CSV â†’ å‘é‡åŒ– â†’ è¿”å›žæœ¯è¯­åˆ—è¡¨
    """
    # âœ… æå–å¤šä¸ª sheet çš„â€œåç§°â€åˆ—
    target_sheets = ["æ‚£è€…åŸºçº¿ä¿¡æ¯", "ç—…æ¡ˆé¦–é¡µä¿¡æ¯"]
    success = extract_name_columns_from_multiple_sheets(
        CONFIG["standard_excel"],
        CONFIG["standard_terms_csv"],
        target_sheets=target_sheets,
        target_column="åç§°"
    )
    if not success:
        raise RuntimeError("æ ‡å‡†æœ¯è¯­æå–å¤±è´¥")

    # âœ… åŠ è½½CSVå¹¶æå–æœ¯è¯­ï¼ˆå³â€œå†…å®¹â€åˆ—ï¼‰
    df = pd.read_csv(CONFIG["standard_terms_csv"])
    if "å†…å®¹" not in df.columns:
        raise ValueError("æ ‡å‡†æœ¯è¯­CSVç¼ºå°‘ 'å†…å®¹' åˆ—")
    terms = df["å†…å®¹"].dropna().astype(str).tolist()
    print(f"âœ… æˆåŠŸåŠ è½½æ ‡å‡†æœ¯è¯­ï¼Œå…± {len(terms)} æ¡")

    # âœ… å‘é‡åŒ–â€œå†…å®¹â€åˆ—
    build_index_from_csv(
        CONFIG["standard_terms_csv"],     # ç›´æŽ¥ä½¿ç”¨åŽŸCSV
        CONFIG["standard_vectors"],       # ä¿å­˜å‘é‡è·¯å¾„
        column_index=2,                   # â€œå†…å®¹â€åˆ—åœ¨CSVä¸­çš„ä½ç½®
        verbose=False
    )
    return terms


def detect_similarity_method(func):
    def wrapper(*args, **kwargs):
        method_name = func.__name__.lower()
        if "bm25" in method_name:
            CONFIG["similarity_method"] = "BM25"
        elif "cosine" in method_name:
            CONFIG["similarity_method"] = "Cosine"
        else:
            CONFIG["similarity_method"] = "Unknown"
        return func(*args, **kwargs)
    return wrapper

# prompt_template = r"""
# ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŒ»ç–—é¢†åŸŸæ•°æ®å¯¹é½åŠ©æ‰‹ï¼Œæ“…é•¿å°†éžæ ‡å‡†åŒ–çš„åŒ»ç–—å­—æ®µåç§°æ˜ å°„åˆ°æ ‡å‡†åŒ–çš„å®šä¹‰ã€‚
# ä½ çš„ä»»åŠ¡æ˜¯æŽ¥æ”¶ä¸€ä¸ª"åŽŸå§‹è¡¨å¤´â€œ ï¼ˆh_textï¼‰å’Œä¸€ä¸ª"å€™é€‰æœ¯è¯­"åˆ—è¡¨ï¼ˆ top_3ï¼‰ï¼Œç„¶åŽä»Žï¼ˆ top_3ï¼‰ä¸­æ‰¾åˆ°ä¸Ž"åŽŸå§‹è¡¨å¤´â€œ ï¼ˆh_textï¼‰æœ€åŒ¹é…çš„å­—æ®µåã€‚
# è¯·æ³¨æ„ä»¥ä¸‹åŒ¹é…è§„åˆ™ï¼š
# 1. **å®Œå…¨åŒ¹é…ä¼˜å…ˆ**ï¼šå¦‚æžœh_textä¸Žtop_3ä¸­çš„æŸä¸ªå­—æ®µåå®Œå…¨ç›¸åŒï¼Œåˆ™è®¤ä¸ºè¿™æ˜¯æœ€å®Œç¾Žçš„åŒ¹é…ã€‚
# 2. **å¿½ç•¥é™å®šè¯æˆ–ç¼–å·**ï¼šh_textä¸­å¯èƒ½åŒ…å«é¢å¤–çš„é™å®šè¯ã€é¡µé¢å±‚çº§ä¿¡æ¯æˆ–ç¼–å·ã€‚åœ¨åŒ¹é…æ—¶ï¼Œè¯·æ³¨æ„è¿™äº›å› ä¸ºé¡µé¢å±‚çº§å…³ç³»è€Œå¸¦å…¥çš„é™å®šè¯å’Œç¼–å·å¯ä»¥å¿½ç•¥ï¼Œä½†æ˜¯å¯¹äºŽæ ¸å¿ƒçš„ä¸€äº›é™å®šè¯éœ€è¦ä¸¥æ ¼åŒºåˆ†ã€‚ä¾‹å¦‚ï¼Œâ€œå‡ºé™¢å…¶ä»–è¯Šæ–­å…¥é™¢ç—…æƒ…3â€è¿™ä¸ªh_textä¸­æœ€å‰é¢çš„â€œå‡ºé™¢â€æ˜Žæ˜¾æ˜¯è¿™ä¸ªé¡µé¢å±‚çº§å«â€œå‡ºé™¢â€ï¼Œä½†æ˜¯å…¶ä¸­çš„â€œå…¥é™¢â€æ˜¯è·Ÿâ€œç—…æƒ…â€åˆåœ¨ä¸€èµ·çš„ï¼Œä¸èƒ½å¿½ç•¥ï¼Œæœ€åŽé¢çš„3å¯ä»¥ç†è§£ä¸ºæ˜¯é¡µé¢ä¸­ä¸€ä¸ªåˆ—è¡¨çš„ç¼–å·ï¼Œä¹Ÿå¯ä»¥å¿½ç•¥ï¼Œæ‰€ä»¥å®ƒæœ€ç»ˆåŒ¹é…åˆ°â€œå…¶ä»–è¯Šæ–­å…¥é™¢ç—…æƒ…â€ã€‚
# 3. **æ¨¡ç³ŠåŒ¹é…**ï¼šå¦‚æžœä¸å­˜åœ¨å®Œå…¨åŒ¹é…ï¼Œè¯·è¿›è¡Œè¯­ä¹‰ä¸Šçš„æ¨¡ç³ŠåŒ¹é…ï¼Œå¯»æ‰¾æœ€æŽ¥è¿‘çš„å«ä¹‰ã€‚
# 4. **æ— åŒ¹é…å¤„ç†**ï¼šå¦‚æžœä½ è®¤ä¸ºtop_3ä¸­æ²¡æœ‰ä¸Žh_textç›¸åŒ¹é…çš„å­—æ®µï¼Œåˆ™å¯¹åº”çš„åŒ¹é…å­—æ®µè®¾ä¸ºN/Aï¼Œåˆ†æ•°è®¾ä¸º0.0
# 5. **ç½®ä¿¡åº¦åˆ†æ•°**ï¼šåˆ†æ•°èŒƒå›´ä¸º(0, 1.0]ï¼Œ1.0è¡¨ç¤ºå®Œç¾ŽåŒ¹é…ã€‚
# è¯·ä¸¥æ ¼ä»¥JSONæ ¼å¼è¿”å›žç»“æžœï¼ŒåŒ…å« matched_field_name å’Œ score ä¸¤ä¸ªå­—æ®µã€‚ä¸è¦åŒ…å«'''jsonå’Œä»»ä½•é¢å¤–çš„è§£é‡Šã€è¯´æ˜Žæˆ–æŠ¥é”™ä¿¡æ¯ã€‚
#
# ---
#
# **è¾“å…¥ç¤ºä¾‹**
# **h_text:** "å‡ºé™¢å…¶ä»–è¯Šæ–­å…¥é™¢ç—…æƒ…3"
# **top_3:** ["å…¥é™¢è¯Šæ–­",  "å…¶ä»–è¯Šæ–­å…¥é™¢ç—…æƒ…", "å…¥é™¢ç—…æƒ…"]
# **è¾“å‡ºç¤ºä¾‹**
# {
#   "matched_field_name": "å…¶ä»–è¯Šæ–­å…¥é™¢ç—…æƒ…",
#   "score": 0.95
# }
#
# **è¾“å…¥ç¤ºä¾‹**
# **h_text:** "å‡ºé™¢å…¶ä»–è¯Šæ–­å‡ºé™¢æƒ…å†µ4"
# **top_3:** ["å…¥é™¢è¯Šæ–­", "ä¸»è¦è¯Šæ–­", "å…¶ä»–è¯Šæ–­"]
# **è¾“å‡ºç¤ºä¾‹**
# {
#   "matched_field_name": "N/A",
#   "score": 0.0
# }
#
# ---
#
# ## ä»»åŠ¡ (Task)
#
# è¯·ä¸¥æ ¼åªè¿”å›žå¦‚ä¸‹ JSON æ ¼å¼ï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–å†…å®¹ï¼š
# {"matched_field_name": "...", "score": ...}
#
# * **è¾“å…¥:**
# **h_text:**: {{h_text}}
# **top_3:**: {{top_3}}
#
# * **è¿”å›ž:**è¯·ä¸¥æ ¼è¿”å›žä¸€æ®µJSON æ ¼å¼ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼ˆä¸åŠ ä»»ä½•è§£é‡Šï¼‰ï¼š
# {"matched_field_name": "...", "score": ...}
# ç¦æ­¢è¿”å›žå¤šä¸ªJSONï¼Œä¸å…è®¸å¸¦è¯´æ˜Žã€æ³¨é‡Šã€æ–‡å­—ã€‚
#
# """
prompt_template = r"""
ä½ æ˜¯åŒ»ç–—æ•°æ®æ ‡å‡†åŒ–åŠ©æ‰‹ã€‚è¯·ä»Žä¸‹åˆ—å€™é€‰æœ¯è¯­ä¸­ï¼Œé€‰æ‹©ä¸Žç»™å®šåŽŸå§‹è¡¨å¤´æœ€åŒ¹é…çš„ä¸€ä¸ªã€‚

åŒ¹é…è§„åˆ™ï¼š
1. å®Œå…¨ä¸€è‡´ä¼˜å…ˆï¼›
2. å¿½ç•¥æ— æ„ä¹‰è¯ï¼ˆå¦‚â€œå‡ºé™¢â€ã€â€œç¼–å·â€ã€â€œ3â€ç­‰ï¼‰ï¼Œä½†ä¿ç•™å¦‚â€œå…¥é™¢â€â€œç—…æƒ…â€ï¼›
3. è‹¥æ— åˆé€‚åŒ¹é…ï¼Œè¿”å›ž N/A å’Œ 0.0 åˆ†ï¼›
4. åˆ†æ•°ä¸º (0, 1.0]ï¼ŒåŒ¹é…è¶ŠæŽ¥è¿‘ï¼Œåˆ†æ•°è¶Šé«˜ï¼›

âš ï¸ã€è¾“å‡ºè¦æ±‚ã€‘
ä¸¥æ ¼ä»…è¾“å‡ºå¦‚ä¸‹æ ¼å¼ï¼Œä¸èƒ½æœ‰è§£é‡Šã€ä»£ç å—ã€æ¢è¡Œæˆ–å…¶å®ƒå†…å®¹ï¼š
{"matched_field_name": "xxx", "score": x.x}

---

åŽŸå§‹è¡¨å¤´: {{h_text}}
å€™é€‰æœ¯è¯­: {{top_3}}
è¯·è¾“å‡ºï¼š
"""


def generate_with_llm(prompt: str) -> str:
    try:
        response = client.chat.completions.create(
            model=CONFIG["llm_model"],
            messages=[{"role": "user", "content": prompt}],
            temperature=0,
            presence_penalty=1.5,
            extra_body={"min_p": 0},
        )

        message_obj = response.choices[0].message
        raw_content = None
        if hasattr(message_obj, "content") and message_obj.content:
            raw_content = message_obj.content.strip()
        elif hasattr(message_obj, "reasoning_content") and message_obj.reasoning_content:
            raw_content = message_obj.reasoning_content.strip()
        else:
            raw_content = ""

        # âœ… åŸºç¡€æ¸…æ´—ï¼šåŽ»é™¤ markdown JSON åŒ…è£¹
        if raw_content.startswith("```json"):
            raw_content = re.sub(r"^```json", "", raw_content).strip()
            raw_content = re.sub(r"```$", "", raw_content).strip()
        elif raw_content.startswith("```"):
            raw_content = re.sub(r"^```", "", raw_content).strip()
            raw_content = re.sub(r"```$", "", raw_content).strip()

        # âœ… æ‰©å±•æ¸…æ´—ï¼šä¸­æ–‡ç¬¦å· + æ‹¼å†™ä¿®å¤ + å†—ä½™å­—æ®µ
        raw_content = raw_content.replace("â€œ", "\"").replace("â€", "\"")
        raw_content = raw_content.replace("ï¼Œ", ",").replace("ï¼š", ":")
        raw_content = raw_content.replace("matchee", "matched_field_name")
        if '"matched_field_' in raw_content:
            raw_content = raw_content.replace('"matched_field_"', '"matched_field_name"')
        raw_content = raw_content.rstrip("ã€‚")

        # âœ… è‡ªåŠ¨è¡¥å…¨ç¼ºå¤±çš„å¤§æ‹¬å·
        if raw_content.count("{") > raw_content.count("}"):
            raw_content += "}"
        elif raw_content.count("{") < raw_content.count("}"):
            raw_content = raw_content[:raw_content.rfind("}")+1]

        # âœ… æ­£åˆ™æå– JSON ä¸»ä½“
        # âœ… æ›´ä¸¥æ ¼çš„æ­£åˆ™æå– JSON ä¸»ä½“ï¼Œç¡®ä¿åªæå–ä¸€æ®µ
        try:
            json_match = re.findall(r"\{.*?\}", raw_content.strip(), re.DOTALL)
            if len(json_match) != 1:
                print(f"âš ï¸ è¿”å›žäº† {len(json_match)} æ®µ JSONï¼Œæ— æ³•åˆ¤æ–­ä½¿ç”¨å“ªæ®µ")
                print(f"Promptï¼š{prompt}")
                print(f"åŽŸå§‹è¿”å›žå†…å®¹ï¼š{raw_content}")
                return "è°ƒç”¨å¤±è´¥"

            parsed = json.loads(json_match[0])
            matched = parsed.get("matched_field_name", "")
            if matched == "N/A":
                return ""
            return matched

            parsed = json.loads(raw_content)
            matched = parsed.get("matched_field_name", "")
            if matched == "N/A":
                return ""
            return matched

        except Exception as e:


            print("âš ï¸ JSONè§£æžå¤±è´¥ï¼")
            print(f"Promptï¼š{prompt}")
            print(f"è¿”å›žåŽŸæ–‡ï¼š{raw_content}")
            print(f"å¼‚å¸¸ä¿¡æ¯ï¼š{e}")
            return "è°ƒç”¨å¤±è´¥"

    except Exception as e:
        print(f"âš ï¸ LLMè°ƒç”¨å¤±è´¥ï¼š{e}")
        return "è°ƒç”¨å¤±è´¥"


threshold_ratio = 0.34
@detect_similarity_method
def calculate_similarities_bm25() -> List[Dict]:
    header_texts = pd.read_csv(CONFIG["header_csv"], header=None)[0].dropna().astype(str).tolist()
    standard_texts = pd.read_csv(CONFIG["standard_terms_csv"])["å†…å®¹"].dropna().astype(str).tolist()
    tokenized_corpus = [list(jieba.cut(text)) for text in standard_texts]
    bm25 = BM25Okapi(tokenized_corpus)
    results = []

    def process_single_header(h_text: str) -> Dict:
        query = list(jieba.cut(h_text))
        scores = bm25.get_scores(query)
        max_global_score = 20.3006  # max(scores)
        top_3_indices = np.argsort(scores)[-3:][::-1]
        top_3 = [standard_texts[i] for i in top_3_indices]
        top_scores = [scores[i] for i in top_3_indices]
        top_score = top_scores[0]

        if top_score < max_global_score * threshold_ratio:
            return {
                "åŽŸå§‹è¡¨å¤´": h_text,
                "å€™é€‰æœ¯è¯­": top_3,
                "LLMé€‰æ‹©": "",  # ä¸è°ƒç”¨LLM
                "æœ€é«˜ç›¸ä¼¼åº¦": round(top_score, 4),
                "æœ€é«˜åˆ†ç›¸å¯¹æ¯”ä¾‹ï¼ˆå½“å‰/maxï¼‰": round(top_score / max_global_score, 4) if max_global_score != 0 else 0,
                "æ˜¯å¦è°ƒç”¨LLM": "å¦"
            }
        else:
            prompt = prompt_template.replace("{{h_text}}", h_text).replace("{{top_3}}",
                                                                           json.dumps(top_3, ensure_ascii=False))
            llm_choice_result = generate_with_llm(prompt)

            # åˆ¤æ–­æ˜¯å¦è°ƒç”¨æˆåŠŸå¹¶è¿”å›žå€¼
            if llm_choice_result == "è°ƒç”¨å¤±è´¥":
                final_choice = "è°ƒç”¨å¤±è´¥"
            else:
                final_choice = llm_choice_result.strip()

            return {
                "åŽŸå§‹è¡¨å¤´": h_text,
                "å€™é€‰æœ¯è¯­": top_3,
                "LLMé€‰æ‹©": final_choice,
                "æœ€é«˜ç›¸ä¼¼åº¦": round(top_score, 4),
                "æœ€é«˜åˆ†ç›¸å¯¹æ¯”ä¾‹ï¼ˆå½“å‰/maxï¼‰": round(top_score / max_global_score, 4) if max_global_score != 0 else 0,
                "æ˜¯å¦è°ƒç”¨LLM": "æ˜¯"
            }
    def process_single_header_with_index(index, h_text):
        result = process_single_header(h_text)
        return index, result

    # æŒ‰åŽŸå§‹é¡ºåºåˆå§‹åŒ–ç©ºåˆ—è¡¨
    results = [None] * len(header_texts)

    with ThreadPoolExecutor(max_workers=20) as executor:
        futures = {
            executor.submit(process_single_header_with_index, idx, h_text): idx
            for idx, h_text in enumerate(header_texts)
        }

        with tqdm(total=len(header_texts), desc="ðŸ§  LLMåŒ¹é…ä¸­", ncols=80) as pbar:
            for future in as_completed(futures):
                try:
                    idx, result = future.result()
                    results[idx] = result
                except Exception as e:
                    future_idx = futures[future]
                    print(f"âš ï¸ è¡¨å¤´å¤„ç†å¤±è´¥ï¼ˆindex={future_idx}ï¼‰: {e}")
                finally:
                    pbar.update(1)

    return results

def save_results(results: List[Dict]):
    results = [r for r in results if r is not None]
    df = pd.DataFrame(results)
    print("ä¿å­˜å‰çš„åˆ—åï¼š", df.columns.tolist())

    # åˆ é™¤ä¸éœ€è¦çš„åˆ—
    df.drop(columns=[col for col in ["å¹³å‡ç›¸ä¼¼åº¦", "åŒ¹é…æˆåŠŸ"] if col in df.columns], inplace=True)

    # åŠ è½½ GT æ ‡å‡†ç­”æ¡ˆï¼ˆè·³è¿‡è¡¨å¤´ï¼‰
    gt_path = "/home/gzy/rag-biomap/dataset/GT.xlsx"
    gt_df = pd.read_excel(gt_path, header=0)

    if gt_df.shape[1] < 2:
        raise ValueError("GT.xlsx å¿…é¡»è‡³å°‘åŒ…å«ä¸¤åˆ—ï¼Œç¬¬äºŒåˆ—ä¸ºæ ‡å‡†ç­”æ¡ˆ")

    gt_answers = gt_df.iloc[:, 1].fillna("").astype(str).tolist()
    df["GTæ ‡å‡†ç­”æ¡ˆ"] = pd.Series(gt_answers[:len(df)])

    # åŒ¹é…åˆ¤æ–­
    df["æ˜¯å¦åŒ¹é…GT"] = df.apply(lambda row: row["LLMé€‰æ‹©"].strip() == row["GTæ ‡å‡†ç­”æ¡ˆ"].strip(), axis=1)

    # ç»Ÿè®¡ä¿¡æ¯
    total_accuracy = df["æ˜¯å¦åŒ¹é…GT"].mean()
    gt_empty_count = sum(df["GTæ ‡å‡†ç­”æ¡ˆ"] == "")
    llm_empty = df["LLMé€‰æ‹©"] == ""
    gt_empty = df["GTæ ‡å‡†ç­”æ¡ˆ"] == ""
    llm_not_empty = df["LLMé€‰æ‹©"] != ""

    llm_empty_and_gt_empty = df[llm_empty & gt_empty].shape[0]
    llm_empty_total = llm_empty.sum()
    llm_not_empty_total = llm_not_empty.sum()
    llm_not_empty_gt_empty = df[llm_not_empty & gt_empty].shape[0]
    llm_empty_gt_not_empty = df[llm_empty & ~gt_empty].shape[0]

    # åˆ›å»ºç»Ÿè®¡ä¿¡æ¯DataFrame
    stats_data = {
        "ç»Ÿè®¡æŒ‡æ ‡": [
            "llmé€‰æ‹©ä¸ŽGTæ ‡å‡†ç­”æ¡ˆåŒ¹é…å‡†ç¡®çŽ‡",
            "GTæ ‡å‡†ç­”æ¡ˆä¸­ç©ºå€¼ä¸ªæ•°",
            "llmé€‰æ‹©ä¸ºç©ºï¼ŒGTä¹Ÿä¸ºç©ºçš„åŒ¹é…æˆåŠŸæ•°é‡",
            "llmé€‰æ‹©ä¸ºç©ºçš„æ•°é‡",
            "llmé€‰æ‹©éžç©ºçš„æ•°é‡",
            "llmé€‰æ‹©éžç©ºï¼Œä½†GTæ˜¯ç©ºçš„æ•°é‡",
            "llmé€‰æ‹©ä¸ºç©ºï¼ŒGTä¸ä¸ºç©ºçš„æ•°é‡"
        ],
        "æ•°å€¼": [
            total_accuracy,
            gt_empty_count,
            llm_empty_and_gt_empty,
            llm_empty_total,
            llm_not_empty_total,
            llm_not_empty_gt_empty,
            llm_empty_gt_not_empty
        ]
    }
    stats_df = pd.DataFrame(stats_data)

    # å°†ç»Ÿè®¡ä¿¡æ¯å†™å…¥Excelçš„ç¬¬12-15åˆ—ï¼ˆL-Oåˆ—ï¼‰
    with pd.ExcelWriter(os.path.join(CONFIG["output_dir"], "é˜ˆå€¼è®¾ç½®34%.xlsx"), engine="openpyxl") as writer:
        df.to_excel(writer, sheet_name="åŒ¹é…ç»“æžœ", index=False)
        stats_df.to_excel(writer, sheet_name="åŒ¹é…ç»“æžœ", startcol=11, startrow=1, index=False, header=False)

    # æŽ§åˆ¶å°è¾“å‡ºï¼ˆè¾…åŠ©ç¡®è®¤ï¼‰
    print(f"âœ… ç»“æžœå·²ä¿å­˜åˆ° {os.path.join(CONFIG['output_dir'], 'é˜ˆå€¼è®¾ç½®34%.xlsx')}")
    print(f"ðŸ“Š åŒ¹é…å‡†ç¡®çŽ‡ï¼š{total_accuracy:.6f}")
    print(f"ðŸ“Š GTä¸ºç©ºå€¼ï¼š{gt_empty_count}ï¼Œllmé€‰æ‹©ä¸ºç©ºæ•°é‡ï¼š{llm_empty_total}")
    print(f"ðŸ“Š llmé€‰æ‹©ä¸ºç©º && GTä¸ºç©ºï¼ˆåŒ¹é…ï¼‰ï¼š{llm_empty_and_gt_empty}")
    print(f"ðŸ“Š llmé€‰æ‹©éžç©º && GTä¸ºç©ºï¼š{llm_not_empty_gt_empty}")
    print(f"ðŸ“Š llmé€‰æ‹©ä¸ºç©º && GTéžç©ºï¼š{llm_empty_gt_not_empty}")
    llm_failed_count = sum(df["LLMé€‰æ‹©"] == "è°ƒç”¨å¤±è´¥")
    print(f"â— LLMè°ƒç”¨å¤±è´¥æ•°é‡ï¼š{llm_failed_count}")



def main():
    from Build_an_index.invoke_Build_index import get_embedding


    #è‡ªåŠ¨è¯†åˆ«å½“å‰ä½¿ç”¨çš„åµŒå…¥æ¨¡åž‹--æ–¹æ³•ï¼šèŽ·å–get_embeddingå‡½æ•°çš„æ¥æºæ¨¡å—è·¯å¾„ï¼ˆæ¯”å¦‚ bge_m3.pyï¼‰
    module_path = get_embedding.__module__

    print(f"ðŸ“ æ£€æµ‹åˆ° get_embedding æ¥è‡ªæ¨¡å—ï¼š{module_path}")  # âœ… ï¼šè°ƒè¯•è¾“å‡º

    if "bge_m3" in module_path:
        CONFIG["embedding_model"] = "bge-m3"
    elif "nomic_embed_text" in module_path:
        CONFIG["embedding_model"] = "nomic-embed-text"
    elif "mxbai_embed_large" in module_path:
        CONFIG["embedding_model"] = "mxbai-embed-large"
    else:
        CONFIG["embedding_model"] = "unknown"

    #CONFIG["embedding_model"] = get_embedding.__defaults__[0]

    # è‡ªåŠ¨æ£€æµ‹å½“å‰å¯ç”¨çš„ç›¸ä¼¼åº¦è®¡ç®—å‡½æ•°æ˜¯å“ªä¸€ä¸ª-é€šè¿‡å…¨å±€å˜é‡è¡¨globals()æ¥æ£€æµ‹å“ªä¸ªå‡½æ•°å­˜åœ¨ï¼Œæ˜¯æˆ‘æœ‰æ²¡æœ‰â€œå®šä¹‰â€å®ƒã€‚
    if "calculate_similarities_bm25" in globals():
        calculate_similarities = calculate_similarities_bm25
    elif "calculate_similarities_cosine" in globals():
        calculate_similarities = calculate_similarities_cosine
    else:
        raise ValueError(
            "æœªæ£€æµ‹åˆ°ç›¸ä¼¼åº¦è®¡ç®—å‡½æ•°ï¼Œè¯·ç¡®ä¿ä¿ç•™ calculate_similarities_bm25 æˆ– calculate_similarities_cosine ä¸­çš„ä¸€ä¸ª")

    initialize_directories()
    print("ðŸ”„ å¤„ç†éžæ ‡å‡†æ•°æ®...")
    header_texts = process_non_standard_data()

    print("ðŸ”„ å¤„ç†æ ‡å‡†çŸ¥è¯†åº“...")
    standard_texts = process_standard_data()

    print("ðŸ” è®¡ç®—ç›¸ä¼¼åº¦å¹¶æ‰§è¡Œç®€åŒ–RAGæµç¨‹...")
    results = calculate_similarities()

#è¿è¡Œç»“æžœæ˜¾ç¤ºï¼šðŸ“ å½“å‰ä½¿ç”¨çš„ç›¸ä¼¼åº¦è®¡ç®—æ–¹æ³•ä¸ºï¼š......
    print(f"ðŸ“ å½“å‰ä½¿ç”¨çš„ç›¸ä¼¼åº¦è®¡ç®—æ–¹æ³•ä¸ºï¼š{CONFIG['similarity_method']}")

    print("ðŸ’¾ ä¿å­˜ç»“æžœ...")
    save_results(results)

if __name__ == "__main__":
    main()
