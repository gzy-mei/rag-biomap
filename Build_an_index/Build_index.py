import pandas as pd
import numpy as np
import requests
import os

def get_embedding(text, model='nomic-embed-text', server_url='http://localhost:11434/api/embeddings'):
    response = requests.post(server_url, json={
        'model': model,
        'prompt': text
    })
    response.raise_for_status()
    return response.json()['embedding']

def vectorize_csv_column(csv_path, save_path_npy, column_index=2):
    df = pd.read_csv(csv_path)
    texts = df.iloc[1:, column_index].dropna().astype(str).tolist()  # è·³è¿‡ç¬¬ä¸€è¡Œ
    embeddings = []

    for i, text in enumerate(texts):
        try:
            embedding = get_embedding(text)
            embeddings.append(embedding)
            print(f"[{i+1}/{len(texts)}] âœ… æˆåŠŸåµŒå…¥ï¼š{text}")
        except Exception as e:
            print(f"[{i+1}] âŒ åµŒå…¥å¤±è´¥ï¼š{text}ï¼ŒåŸå› ï¼š{e}")

    np.save(save_path_npy, np.array(embeddings, dtype=np.float32))
    print(f"\nğŸ‰ å‘é‡åŒ–å®Œæˆï¼ä¿å­˜åˆ°ï¼š{save_path_npy}ï¼Œå…± {len(embeddings)} æ¡")

if __name__ == "__main__":
    csv_path = "/home/gzy/rag-biomap/data_description/æ ‡å‡†æœ¯è¯­åˆå¹¶ç»“æœ.csv"
    save_path_npy = "/home/gzy/rag-biomap/Build_an_index/standard_terms.npy"
    vectorize_csv_column(csv_path, save_path_npy)
